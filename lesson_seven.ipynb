{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Lesson Seven"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Let's import from lesson_six\n",
    "import lesson_six as lesson_six\n",
    "# Rest the graph\n",
    "lesson_six.reset_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "# Instanciat the data\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "# The shape of the data is (20640, 8) this will return m is the number of rows, n is the number of column\n",
    "m, n = housing.data.shape \n",
    "#housing_data_and_bias = np.c_[np.ones((m, 1)), housing.data]\n",
    "\n",
    "# We have to standardiaze the input data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Instantiate the preprocessing object\n",
    "scaler = StandardScaler() \n",
    "\n",
    "# This will standardize the input data, the shape will be (m, 8)\n",
    "scaled_housing_data = scaler.fit_transform(housing.data) \n",
    "\n",
    "# This will add bias, this will add column at index 0, the shape will be (m, 8+1) \n",
    "scaled_housing_data_and_bias = np.c_[np.ones((m, 1)), scaled_housing_data] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Using TensorFlow's Gradient Descent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "lesson_six.reset_graph()\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Wrap the scaled_housing_data_and_bias with tf.constant()\n",
    "X = tf.constant(scaled_housing_data_and_bias, dtype=tf.float32, name=\"X\")\n",
    "\n",
    "# Wrpa the housing.target (reshape it from (n,) to (n,1)) with tf.constant()\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "\n",
    "# Compute the theta with tf.random_uniform() use the number of column add 1 so it will match the X+bias columns\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=1), name=\"theta\")\n",
    "\n",
    "# Compute the y_hat using tf.matmul()\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "\n",
    "# Get the error\n",
    "error = y_pred - y\n",
    "\n",
    "# Compute the Mean Square Error using tf.reduce_mean() and tf.square(error)\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TensorFlow's autodiff feature can automatically compute the gradient for us. \n",
    "# Simply add the following line of code.\n",
    "gradients = tf.gradients(mse, [theta])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The tf.gradients() function takes mse and a list  of variables [theta] and it creates a list of operations one per variable to compute the gradients of the operation with regards to each variable. So this will return the gradient vector of the MSE with regards to theta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 MSE=  14.5535\n",
      "Epoch:  100 MSE=  0.837282\n",
      "Epoch:  200 MSE=  0.561952\n",
      "Epoch:  300 MSE=  0.546907\n",
      "Epoch:  400 MSE=  0.540841\n",
      "Epoch:  500 MSE=  0.536597\n",
      "Epoch:  600 MSE=  0.533485\n",
      "Epoch:  700 MSE=  0.531191\n",
      "Epoch:  800 MSE=  0.529492\n",
      "Epoch:  900 MSE=  0.528231\n",
      "Best theta:  [[ 2.06855226]\n",
      " [ 0.84201318]\n",
      " [ 0.13798265]\n",
      " [-0.25731888]\n",
      " [ 0.28500068]\n",
      " [ 0.00233129]\n",
      " [-0.04121713]\n",
      " [-0.7480495 ]\n",
      " [-0.71861744]]\n"
     ]
    }
   ],
   "source": [
    "# Optimizer\n",
    "training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "\n",
    "# Globa variable initializer\n",
    "global_init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(global_init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch: \", epoch, \"MSE= \", mse.eval())\n",
    "        sess.run(training_op)\n",
    "    best_theta = theta.eval()\n",
    "    \n",
    "print(\"Best theta: \", best_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "lesson_six.reset_graph()\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Wrap the scaled_housing_data_and_bias with tf.constant()\n",
    "X = tf.constant(scaled_housing_data_and_bias, dtype=tf.float32, name=\"X\")\n",
    "\n",
    "# Wrpa the housing.target (reshape it from (n,) to (n,1)) with tf.constant()\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "\n",
    "# Compute the theta with tf.random_uniform() use the number of column add 1 so it will match the X+bias columns\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "\n",
    "# Compute the y_hat using tf.matmul()\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "\n",
    "# Get the error\n",
    "error = y_pred - y\n",
    "\n",
    "# Compute the Mean Square Error using tf.reduce_mean() and tf.square(error)\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "TensorFlow also provides a number of optimizer, such as the GradientDescentOptimizer() and the MeMentumOptimizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Gradient Decscent with optimizer\n",
    "#optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.5)\n",
    "training_op = optimizer.minimize(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 MSE=  12.2318\n",
      "Epoch:  100 MSE=  0.798976\n",
      "Epoch:  200 MSE=  0.66714\n",
      "Epoch:  300 MSE=  0.599869\n",
      "Epoch:  400 MSE=  0.564523\n",
      "Epoch:  500 MSE=  0.545875\n",
      "Epoch:  600 MSE=  0.535987\n",
      "Epoch:  700 MSE=  0.530709\n",
      "Epoch:  800 MSE=  0.527867\n",
      "Epoch:  900 MSE=  0.526322\n",
      "Best theta:  [[  2.06855559e+00]\n",
      " [  8.37727904e-01]\n",
      " [  1.30713731e-01]\n",
      " [ -2.61316836e-01]\n",
      " [  2.93626070e-01]\n",
      " [ -2.56629748e-04]\n",
      " [ -4.05110605e-02]\n",
      " [ -8.05071473e-01]\n",
      " [ -7.75725722e-01]]\n"
     ]
    }
   ],
   "source": [
    "# Globa variable initializer\n",
    "global_init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Pass the global_init to the sess.run()\n",
    "    sess.run(global_init)\n",
    "    \n",
    "    # Iterate for training \n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        # Print the MSE every 100 iteration\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch: \", epoch, \"MSE= \", mse.eval())\n",
    "            \n",
    "        # Pass the optimizer.minimize(mse) on each iteration\n",
    "        sess.run(training_op)\n",
    "        \n",
    "    # Evaluate the theta to get a list of the best theta (9,1)\n",
    "    best_theta = theta.eval()\n",
    "    \n",
    "print(\"Best theta: \", best_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "lesson_six.reset_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Placeholder Nodes\n",
    "\n",
    "Placeholder nodes is just to output the data at runtime, it dosen't perform any computation, and it is used to pass the training data to TensorFlow during trainin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create a placeholder node, we invoke the placeholder() function, and pass the data type and the shape(optional)\n",
    "# Here we define the spape to be (n, 3) any rows, but 3 columns\n",
    "A = tf.placeholder(tf.float32, shape=(None, 3))\n",
    "\n",
    "# B is a node depends on A\n",
    "B = A + 5\n",
    "\n",
    "# Now lets do the computation\n",
    "with tf.Session() as sess:\n",
    "    # Evaluate B, by passing data to A using feed_dict={...}\n",
    "    B_val_1 = B.eval(feed_dict={A: [[1, 2, 3]]})\n",
    "    B_val_2 = B.eval(feed_dict={A: [[4, 5, 6], [7, 8, 9]]})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.  7.  8.]]\n"
     ]
    }
   ],
   "source": [
    "print(B_val_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  9.  10.  11.]\n",
      " [ 12.  13.  14.]]\n"
     ]
    }
   ],
   "source": [
    "print(B_val_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "lesson_six.reset_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Mini-batch Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "To implement Mini-batch Gradient Descent we will use a placeholder() node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 1000\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Change the definition of X and y in the construction phase to make them a placeholder nodes.\n",
    "X = tf.placeholder(tf.float32, shape=(None, n + 1), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "\n",
    "# Compute the theta with tf.random_uniform() use the number of column add 1 so it will match the X+bias columns\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "\n",
    "# Compute the y_hat using tf.matmul()\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "\n",
    "# Get the error\n",
    "error = y_pred - y\n",
    "\n",
    "# Compute the Mean Square Error using tf.reduce_mean() and tf.square(error)\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "\n",
    "# Gradient Decscent with optimizer\n",
    "#optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.5)\n",
    "training_op = optimizer.minimize(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Define the batch size and compute the total number of batches:\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# In the execution phase: we will fetch the mini-batches one by one, then provide the value of X and y via using \n",
    "# feed_dict parameter when evaluating a node that depends on either of them\n",
    "\n",
    "def fetch_batch(epoch, batch_index, batch_size):\n",
    "    '''\n",
    "    This fucntion will return the X_batch, y_batch with random indices\n",
    "    '''\n",
    "    \n",
    "    # Find a random indices whithin the size of the dataset\n",
    "    np.random.seed(epoch * n_batches + batch_index)\n",
    "    indices = np.random.randint(m, size=batch_size)\n",
    "    \n",
    "    # Pich the X and y batches using the random indices\n",
    "    X_batch = scaled_housing_data_and_bias[indices]\n",
    "    y_batch = housing.target.reshape(-1, 1)[indices]\n",
    "    return X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "Epoch:  100\n",
      "Epoch:  200\n",
      "Epoch:  300\n",
      "Epoch:  400\n",
      "Epoch:  500\n",
      "Epoch:  600\n",
      "Epoch:  700\n",
      "Epoch:  800\n",
      "Epoch:  900\n"
     ]
    }
   ],
   "source": [
    "# Globa variable initializer\n",
    "global_init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(global_init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        # Print the MSE every 100 iteration\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch: \", epoch)\n",
    "        \n",
    "        for batch_index in range(n_batches):\n",
    "            \n",
    "            # Get the X_batch and the y_batch from the function fetch_batch()\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            \n",
    "            # Evaluate the \n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "\n",
    "    # We don't need to pass the value X and y when evaluating theta since it does not depend on either of them.\n",
    "    best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.049927  ],\n",
       "       [ 0.8267504 ],\n",
       "       [ 0.11433333],\n",
       "       [-0.23890038],\n",
       "       [ 0.31248516],\n",
       "       [ 0.03146332],\n",
       "       [-1.4988426 ],\n",
       "       [-0.87141562],\n",
       "       [-0.83012849]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Saving and restoring a model\n",
    "TensorFlow makes saving and restoring a model very easy. We only need to create a Server node after all variables nodes are created, then, during running phase just invoke the save() method, passing it the session and the path of the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "Epoch:  100\n",
      "Epoch:  200\n",
      "Epoch:  300\n",
      "Epoch:  400\n",
      "Epoch:  500\n",
      "Epoch:  600\n",
      "Epoch:  700\n",
      "Epoch:  800\n",
      "Epoch:  900\n"
     ]
    }
   ],
   "source": [
    "lesson_six.reset_graph()\n",
    "\n",
    "n_epochs = 1000                                                     \n",
    "learning_rate = 0.01                                                                \n",
    "\n",
    "# Change the definition of X and y in the construction phase to make them a placeholder nodes.\n",
    "X = tf.placeholder(tf.float32, shape=(None, n + 1), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "\n",
    "# Compute the theta with tf.random_uniform() use the number of column add 1 so it will match the X+bias columns\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "\n",
    "# Compute the y_hat using tf.matmul()\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")   \n",
    "\n",
    "# Get the error\n",
    "error = y_pred - y             \n",
    "\n",
    "# Compute the Mean Square Error using tf.reduce_mean() and tf.square(error)\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")        \n",
    "\n",
    "# Gradient Decscent with optimizer\n",
    "#optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "optimizer =  tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.5) \n",
    "training_op = optimizer.minimize(mse) \n",
    "\n",
    "# Define the batch size and compute the total number of batches:\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "# Globa variable initializer\n",
    "global_init = tf.global_variables_initializer()\n",
    "\n",
    "# Invoke saver() here at the end of construction phase\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(global_init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        # Print the MSE every 100 iteration\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch: \", epoch)\n",
    "            \n",
    "            # Save\n",
    "            save_path = saver.save(sess, \"/Volumes/MacAndroidStudio/ml-books/savedModel/my_model.ckpt\")\n",
    "        \n",
    "        for batch_index in range(n_batches):\n",
    "            \n",
    "            # Get the X_batch and the y_batch from the function fetch_batch()\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            \n",
    "            # Evaluate the \n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "\n",
    "    # We don't need to pass the value X and y when evaluating theta since it does not depend on either of them.\n",
    "    best_theta = theta.eval()\n",
    "    \n",
    "    # Save\n",
    "    save_path = saver.save(sess, \"/Volumes/MacAndroidStudio/ml-books/savedModel/my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.049927  ],\n",
       "       [ 0.8267504 ],\n",
       "       [ 0.11433333],\n",
       "       [-0.23890038],\n",
       "       [ 0.31248516],\n",
       "       [ 0.03146332],\n",
       "       [-1.4988426 ],\n",
       "       [-0.87141562],\n",
       "       [-0.83012849]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "To restore, we can create a tf.train.Saver() just to replace tf.global_variables_initializer() and then within the with block we invoke saver.restore() pass the sess instance and the path as argument.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# This will restore a saved model, including both the graph structure and the variable values, \n",
    "# without having to search for the code that built it.\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"/Volumes/MacAndroidStudio/ml-books/savedModel/my_model_final.ckpt\")\n",
    "    best_theta_restored = theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.049927  ],\n",
       "       [ 0.8267504 ],\n",
       "       [ 0.11433333],\n",
       "       [-0.23890038],\n",
       "       [ 0.31248516],\n",
       "       [ 0.03146332],\n",
       "       [-1.4988426 ],\n",
       "       [-0.87141562],\n",
       "       [-0.83012849]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_theta_restored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
