{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Lesson Six"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "TensorFlow according to the documentation: is a powerflow open source software library released in 2015 by Google to make it wasier to design, build, and train deep learning models. At a high level, TensorFlow is a Python library that allows users to express arbitrary computation as a graph of data flows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reset_graph(seed=1):\n",
    "    '''\n",
    "    To reset some random\n",
    "    '''\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Where to save the figures\n",
    "def save_data(fig_id, tight_layout=True, PROJECT_ROOT_DIR = \".\", LESSON_ID = \"tensorflow\"):\n",
    "    '''\n",
    "    Saving figures\n",
    "    '''\n",
    "    path = os.path.join(PROJECT_ROOT_DIR, \"images\", LESSON_ID, fig_id + \".png\")\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets start the lesson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Resert all parameters \n",
    "reset_graph()\n",
    "\n",
    "# Create a graph, well this does not perform ny computation, it just creates a graph.\n",
    "x = tf.Variable(3, name=\"X\")\n",
    "y = tf.Variable(4, name=\"y\")\n",
    "f = x+y\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Session() instance, this is what we need to initialize the variables and evaluate f.\n",
    "# The Session() takes care of placing the operations onto devices such as CPUs, GPUs or TPUs and running them. \n",
    "sess = tf.Session()\n",
    "# run() pass the x variable with initializer \n",
    "sess.run(x.initializer)\n",
    "# run() pass the x variable with initializer \n",
    "sess.run(y.initializer)\n",
    "# run() f this will return x + y = 7\n",
    "result = sess.run(f) \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# And finally close the Session() to frees up resources\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "# we can also use with block, using this way we dont have to invoke close()\n",
    "with tf.Session() as sess:\n",
    "    x.initializer.run() # this is equivalent to calling tf.get_default_session().run(x.initializer)\n",
    "    y.initializer.run() # this is equivalent to calling tf.get_default_session().run(x.initializer)\n",
    "    result = f.eval() # this is equivalent to calling tf.get_default.session().run(f)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "# Instead of manually running the initializer one for each variable, \n",
    "# we can use the global_variables_initializer()\n",
    "global_init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    global_init.run() # This will initilaize all the variables\n",
    "    result = f.eval()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "# Another way is to use tf.InteractiveSession() it will automatically sets itself as the default session,\n",
    "# so we dont need the with block but we need to invoke close() to free resources.\n",
    "sess = tf.InteractiveSession()\n",
    "global_init = tf.global_variables_initializer()\n",
    "global_init.run()\n",
    "result = f.eval()\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# and dont foreget to close\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In TensorFlow we refere the computation graph as the Construction Phase, which is typically builds a computation graph representing the Model and the algorithm to train it. Next will come the Execution Phase which will loop to evaluates a training step like one step for each mini-batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "# Now, any node we create will be added to the default graph\n",
    "Xx = tf.Variable(5, name=\"Xx\")\n",
    "Xx.graph is tf.get_default_graph() # this should return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Variable/read:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# But we may want to create a temporarily graph and making it the default graph inside the with block:\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    x_temp = tf.Variable(10)\n",
    "print(x_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This will return True\n",
    "x_temp.graph is graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This will return False\n",
    "x_temp is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Final we better to avoid dublicate nodes, we must invoke tf.reset_default_graph()\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "w = tf.constant(10)\n",
    "x = w + 1\n",
    "y = x + 2\n",
    "z = x * 3\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(y.eval())  # TensorFlow will automatically detects that y depends on x, which depends on w.\n",
    "    print(z.eval())  # TensorFlow will automatically detects that z depends on x, which depends on w."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13   33\n"
     ]
    }
   ],
   "source": [
    "# We can evaluate y and z efficiently, without evaluating w and x twice as in the code above, we can do like this:\n",
    "with tf.Session() as sess:\n",
    "    y_eval, z_eval = sess.run([y, z])\n",
    "\n",
    "print(y_eval, \" \", z_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take note that in single-proces TensorFlow, multiple sessions do not share any state. But in distributed TensorFlow, variable state is stored on the servers, not in the sessions, so multiple sessions can share the same variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow operations can take any number of inputs and return any number of outputs. According to the documentations: The central unit of data in TensorFlow is the tensor. A tensor consists of a set of primitive values shaped into an array of any number of dimensions. A tensor's rank is its number of dimensions. Here are some examples of tensors:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[1.0, 2.0, 3.0]], [[7.0, 8.0, 9.0]]]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3 # a rank 0 tensor; this is a scalar with shape []\n",
    "[1. ,2., 3.] # a rank 1 tensor; this is a vector with shape [3]\n",
    "[[1., 2., 3.], [4., 5., 6.]] # a rank 2 tensor; a matrix with shape [2, 3]\n",
    "[[[1., 2., 3.]], [[7., 8., 9.]]] # a rank 3 tensor with shape [2, 1, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can perform computations on arrays of any shape. SO the definition of theta corresponds to the Normal Equation ("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The theta is a Threshold value of an artificial neuron.\n",
    "reset_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading Cal. housing from http://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.tgz to /Users/hishmadabubakaralamudi/scikit_learn_data\n"
     ]
    }
   ],
   "source": [
    "# Get the dataset from sklearn\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "m, n = housing.data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   1.            8.3252       41.         ...,    2.55555556   37.88\n",
      "  -122.23      ]\n",
      " [   1.            8.3014       21.         ...,    2.10984183   37.86\n",
      "  -122.22      ]\n",
      " [   1.            7.2574       52.         ...,    2.80225989   37.85\n",
      "  -122.24      ]\n",
      " ..., \n",
      " [   1.            1.7          17.         ...,    2.3256351    39.43\n",
      "  -121.22      ]\n",
      " [   1.            1.8672       18.         ...,    2.12320917   39.43\n",
      "  -121.32      ]\n",
      " [   1.            2.3886       16.         ...,    2.61698113   39.37\n",
      "  -121.24      ]]\n"
     ]
    }
   ],
   "source": [
    "housing_data_and_bias = np.c_[np.ones((m, 1)), housing.data]\n",
    "print(housing_data_and_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.constant(housing_data_and_bias, dtype=tf.float32, name=\"X\")\n",
    "\n",
    "# Reshape the argets y from (n,) into (n, 1) array\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:  Tensor(\"X:0\", shape=(20640, 9), dtype=float32)  y:  Tensor(\"y:0\", shape=(20640, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(\"X: \", X, \" y: \", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lets calculate the theta using TensorFlow, then later we will compare with NumPy's calculation\n",
    "XT = tf.transpose(X)\n",
    "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT, X)), XT), y)\n",
    "with tf.Session() as sess:\n",
    "    theta_value = theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -3.69419202e+01],\n",
       "       [  4.36693293e-01],\n",
       "       [  9.43577803e-03],\n",
       "       [ -1.07322041e-01],\n",
       "       [  6.45065694e-01],\n",
       "       [ -3.97638942e-06],\n",
       "       [ -3.78654265e-03],\n",
       "       [ -4.21314378e-01],\n",
       "       [ -4.34513755e-01]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The benefit of the above code compared to computing the Normal Equation directly using NumPy is that TensorFlow will automatically run this on our GPU card if we have one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -3.69419202e+01]\n",
      " [  4.36693293e-01]\n",
      " [  9.43577803e-03]\n",
      " [ -1.07322041e-01]\n",
      " [  6.45065694e-01]\n",
      " [ -3.97638942e-06]\n",
      " [ -3.78654266e-03]\n",
      " [ -4.21314378e-01]\n",
      " [ -4.34513755e-01]]\n"
     ]
    }
   ],
   "source": [
    "# Let's compare with NumPy\n",
    "X = housing_data_and_bias\n",
    "y = housing.target.reshape(-1, 1) # Reshape the argets y from (n,) into (n, 1) array\n",
    "yy = housing.target\n",
    "theta_numpy = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)\n",
    "\n",
    "print(theta_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -3.69419202e+01]\n",
      " [  4.36693293e-01]\n",
      " [  9.43577803e-03]\n",
      " [ -1.07322041e-01]\n",
      " [  6.45065694e-01]\n",
      " [ -3.97638942e-06]\n",
      " [ -3.78654265e-03]\n",
      " [ -4.21314378e-01]\n",
      " [ -4.34513755e-01]]\n"
     ]
    }
   ],
   "source": [
    "# Let's compare with Scikit-Learn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lin_regs = LinearRegression()\n",
    "lin_regs.fit(housing.data, housing.target.reshape(-1, 1))\n",
    "theta_sklearn = np.r_[lin_regs.intercept_.reshape(-1, 1), lin_regs.coef_.T]\n",
    "print(theta_sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
